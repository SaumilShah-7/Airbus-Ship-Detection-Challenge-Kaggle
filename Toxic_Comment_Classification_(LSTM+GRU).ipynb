{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Fasttext+Glove Pytorch (Comment Classification).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaumilShah-7/Airbus-Ship-Detection-Challenge-Kaggle/blob/master/Toxic_Comment_Classification_(LSTM%2BGRU).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0e2c7b71-1a29-434f-a066-36d4e46dfa04",
        "_cell_guid": "753ad2eb-eefa-4274-bb67-1b34c9738fd3",
        "trusted": true,
        "id": "6VRSAnwes91m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import gc\n",
        "from tqdm.notebook import tqdm_notebook as tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.keras.preprocessing import text, sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1d3f6356-6913-49cd-8328-07d0857814b1",
        "_cell_guid": "2f9608c5-03ec-4e60-99b3-c46ff99c2dba",
        "trusted": true,
        "id": "5ZH2FHj1s91w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q -o '../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip'\n",
        "!unzip -q -o '../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip'\n",
        "!unzip -q -o '../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b47387c5-a2b8-411c-a028-be0a47c98525",
        "_cell_guid": "43272362-7056-4f8a-9b0c-c5abf4dccf63",
        "trusted": true,
        "id": "Cw1-Mq4os913",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test  = pd.read_csv('test.csv')\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "17567cc8-5050-42f1-b078-ce9dc7edc04f",
        "_cell_guid": "b5022ea4-2f96-4501-a2aa-7849e9e6c6e0",
        "trusted": true,
        "id": "_EhI0qC6s91-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import regex as re\n",
        "!pip install Unidecode\n",
        "from unidecode import unidecode\n",
        "\n",
        "words_only = re.compile(r'[^A-Za-z\\']')\n",
        "def clean_text(x):\n",
        "    x_ascii = unidecode(x)\n",
        "    x_clean = words_only.sub(' ', x_ascii)\n",
        "    return x_clean\n",
        "\n",
        "train['clean_text'] = train['comment_text'].apply(lambda x: clean_text(x))\n",
        "test['clean_text'] = test['comment_text'].apply(lambda x: clean_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "22067121-98db-465d-b6dd-2f5eca0b9564",
        "_cell_guid": "8b353668-dd7d-4a95-b908-cb00f8301a25",
        "trusted": true,
        "id": "07o1DkL8s92I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train['comment_text'][1])\n",
        "print(train['clean_text'][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "cbc3a670-2f61-49f0-80cc-0b301ef5543f",
        "_cell_guid": "8206c4d7-7ac1-4279-9018-dc056dd71b92",
        "trusted": true,
        "id": "entRn9bfs92O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['clean_text'].fillna('something')\n",
        "print(train[train.clean_text=='something'])\n",
        "test['clean_text'].fillna('something')\n",
        "print(test[test.clean_text=='something'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "dec5a060-f27e-4ffa-8e8f-a053aa216cc3",
        "_cell_guid": "546225d9-dc76-4d2d-afdb-337041f36144",
        "trusted": true,
        "id": "ztklPRmks92U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 250000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "34083a5c-87c3-4960-aebc-a40f78a48266",
        "_cell_guid": "b996af4e-3ff0-4a54-97e8-d6437dc68d06",
        "trusted": true,
        "id": "rYzCQ8qvs92a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = text.Tokenizer(num_words=max_features)\n",
        "t.fit_on_texts(list(train['clean_text'])+list(test['clean_text']))\n",
        "\n",
        "print(len(t.word_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "238e6c18-812c-4489-bfbf-51d052470300",
        "_cell_guid": "4889bc65-7ca9-417b-a03f-e559a2b2ad0a",
        "trusted": true,
        "id": "MALKMCphs92g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = t.word_index\n",
        "word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "395bc1c7-1f65-42b5-af68-5785407ccf69",
        "_cell_guid": "ddb053eb-e80f-44ad-bb5a-448b08c69354",
        "trusted": true,
        "id": "2BCwh5eks92l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = t.texts_to_sequences(train['clean_text'])\n",
        "X_test = t.texts_to_sequences(test['clean_text'])\n",
        "\n",
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f9918a30-ee72-47e6-af0c-bf3f2c5b6176",
        "_cell_guid": "8d47618f-57c2-4a79-8269-16dfb75c5721",
        "trusted": true,
        "id": "J9_A0UCts92q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = list(map(len, X_train))\n",
        "print('Min: %d, Mean: %d, Q3: %d, Max: %d' %(min(l), sum(l)/len(l), np.percentile(l, 75), max(l)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "16ab926c-b6f8-4513-9425-b56c79a34836",
        "_cell_guid": "6b830ef5-cdac-4027-9ed3-a54220e2cd20",
        "trusted": true,
        "id": "ldk3oHqqs92v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toxicity_columns = list(train.columns)[2:-1]\n",
        "print(toxicity_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b126e24b-6bee-414f-bd67-8adbfbd40373",
        "_cell_guid": "f4e260d6-a5f7-4779-be2e-ebb556dd993a",
        "trusted": true,
        "id": "eNtMdkQFs921",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 900\n",
        "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "\n",
        "y_train = train[toxicity_columns].values\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(toxicity_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0816e293-381b-4c60-a8f1-26a34c148951",
        "_cell_guid": "8365ff84-4163-49da-9bc6-f4d56f207c15",
        "trusted": true,
        "id": "mniqQLjts926",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('x_train.npy', x_train)\n",
        "np.save('x_test.npy', x_test)\n",
        "np.save('y_train.npy', y_train)\n",
        "\n",
        "with open('word_index.pickle', 'wb') as handle:\n",
        "  pickle.dump(word_index, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "09f0174a-a97f-4783-a613-49a54afb7a1e",
        "_cell_guid": "4d90f97d-81f7-4b26-a383-c02486734e97",
        "trusted": true,
        "id": "jdEv5WQhs93A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del X_train, X_test, x_train, x_test, y_train, t, word_index, l\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4ad7178b-8536-4e6e-8a21-1fcc53c0b6ef",
        "_cell_guid": "3e1ba4ca-648b-40eb-863e-c226e40e26bb",
        "trusted": true,
        "id": "0_AAlpP2s93F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ft_path = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\n",
        "gl_path = '../input/glovetwitter27b100dtxt/glove.twitter.27B.200d.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f348cdf9-cb59-4626-96d3-e9ee4d763df4",
        "_cell_guid": "ded9db8e-4c8a-4120-a37a-aca0ac4c9d8a",
        "trusted": true,
        "id": "AEYBw975s93K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word,*arr):\n",
        "  return word, np.asarray(arr, dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "54c7e486-8b4c-48d6-9190-faff1edc6032",
        "_cell_guid": "2284920f-eec3-456b-9dae-d711e87b25e2",
        "trusted": true,
        "_kg_hide-output": false,
        "id": "YmVkWYrLs93S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import gensim\n",
        "# model = gensim.models.KeyedVectors.load_word2vec_format(ft_path)\n",
        "\n",
        "# words = model.index2word\n",
        "\n",
        "# w_rank = {}\n",
        "# for i,word in enumerate(words):\n",
        "#     w_rank[word] = i\n",
        "\n",
        "# WORDS = w_rank\n",
        "\n",
        "# del model, words, w_rank\n",
        "# gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b67b83a7-9f65-48fc-9260-634053c5b363",
        "_cell_guid": "ded46422-c2cf-4fc6-9eb3-f788e4e2fb48",
        "trusted": true,
        "id": "DncKLy2Xs93Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "# def P(word): \n",
        "#     \"Probability of `word`.\"\n",
        "#     # use inverse of rank as proxy\n",
        "#     # returns 0 if the word isn't in the dictionary\n",
        "#     return - WORDS.get(word, 0)\n",
        "\n",
        "# def correction(word): \n",
        "#     \"Most probable spelling correction for word.\"\n",
        "#     return max(candidates(word), key=P)\n",
        "\n",
        "# def candidates(word): \n",
        "#     \"Generate possible spelling corrections for word.\"\n",
        "#     return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "# def known(words): \n",
        "#     \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "#     return set(w for w in words if w in WORDS)\n",
        "\n",
        "# def edits1(word):\n",
        "#     \"All edits that are one edit away from `word`.\"\n",
        "#     letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "#     splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "#     deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "#     transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "#     replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "#     inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "#     return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "# def edits2(word): \n",
        "#     \"All edits that are two edits away from `word`.\"\n",
        "#     return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "22ad9b11-2985-4303-b74c-4029c189d703",
        "_cell_guid": "a6eed043-7866-4b45-8688-24cffa7d931f",
        "trusted": true,
        "id": "V0NA4vges93c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('word_index.pickle', 'rb') as handle:\n",
        "    word_index = pickle.load(handle)\n",
        "\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embed_size = 500\n",
        "word_process = re.compile(r'[^A-Za-z]')\n",
        "\n",
        "def getword(embeddings_keys, word):\n",
        "    if word in embeddings_keys:\n",
        "        return word\n",
        "    elif word.lower() in embeddings_keys:\n",
        "        return word.lower()\n",
        "    elif word.upper() in embeddings_keys:\n",
        "        return word.upper()\n",
        "    elif word.capitalize() in embeddings_keys:\n",
        "        return word.capitalize()\n",
        "    elif word_process.sub('', word) in embeddings_keys:\n",
        "        return word_process.sub('', word)\n",
        "    elif len(word)>1 and len(word)<=15:\n",
        "        x = correction(word)\n",
        "        if x in embeddings_keys:\n",
        "            return x\n",
        "\n",
        "    return None\n",
        "\n",
        "def build_matrix(nb_words, embed_size):\n",
        "    embeddings_ft = dict(get_coefs(*o.strip().split()) for o in open(ft_path))\n",
        "    embeddings_gl = dict(get_coefs(*o.strip().split()) for o in open(gl_path))\n",
        "    embeddings_keys_ft = list(embeddings_ft.keys())\n",
        "    \n",
        "    corrected = []\n",
        "    words_not_found = []\n",
        "    matrix = np.zeros((nb_words, embed_size))\n",
        "    \n",
        "    for word, i in tqdm(word_index.items()):\n",
        "        if i >= nb_words:\n",
        "            break\n",
        "        else:\n",
        "            word2 = getword(embeddings_keys_ft, word)\n",
        "            if word2 is not None:\n",
        "                matrix[i, :300] = embeddings_ft.get(word2)\n",
        "                if embeddings_gl.get(word2) is not None:\n",
        "                    matrix[i, 300:] = embeddings_gl.get(word2)\n",
        "                if word2 != word:\n",
        "                    corrected.append((word, word2))\n",
        "            else:\n",
        "                words_not_found.append(word)\n",
        "                matrix[i, :300]=embeddings_ft.get(\"something\")\n",
        "                matrix[i, 300:]=embeddings_gl.get(\"something\")\n",
        "                \n",
        "    return matrix, corrected, words_not_found\n",
        "\n",
        "def build_matrix_1(nb_words, embed_size, correction_map):\n",
        "    embeddings_ft = dict(get_coefs(*o.strip().split()) for o in open(ft_path))\n",
        "    embeddings_gl = dict(get_coefs(*o.strip().split()) for o in open(gl_path))\n",
        "    embeddings_keys_ft = list(embeddings_ft.keys())\n",
        "    \n",
        "    corrected = []\n",
        "    words_not_found = []\n",
        "    matrix = np.zeros((nb_words, embed_size))\n",
        "    \n",
        "    for word, i in tqdm(word_index.items()):\n",
        "        if i >= nb_words:\n",
        "            break\n",
        "        else:\n",
        "            if embeddings_ft.get(word) is not None:\n",
        "                matrix[i, :300] = embeddings_ft.get(word)\n",
        "                if embeddings_gl.get(word) is not None:\n",
        "                    matrix[i, 300:] = embeddings_gl.get(word)\n",
        "            elif correction_map.get(word) is not None:\n",
        "                word2 = correction_map.get(word)\n",
        "                matrix[i, :300] = embeddings_ft.get(word2)\n",
        "                if embeddings_gl.get(word2) is not None:\n",
        "                    matrix[i, 300:] = embeddings_gl.get(word2)\n",
        "                corrected.append((word, word2))\n",
        "            else:\n",
        "                words_not_found.append(word)\n",
        "                matrix[i, :300]=embeddings_ft.get(\"something\")\n",
        "                matrix[i, 300:]=embeddings_gl.get(\"something\")\n",
        "        \n",
        "                \n",
        "    return matrix, corrected, words_not_found"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "6f74e843-ceff-42ff-ae68-2d017e5fdaac",
        "_cell_guid": "ce34dcf6-5e8b-4c59-bf9f-27a041b0ffed",
        "trusted": true,
        "id": "fqB9uIQds93f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('../input/mapping/correction_map_final.pickle', 'rb') as handle:\n",
        "    correction_map = pickle.load(handle)\n",
        "\n",
        "print(len(correction_map))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f1906bcf-6c3c-4093-aa9d-42c46ecc6430",
        "_cell_guid": "711c237c-27c3-47a0-960a-e7e2f870b42c",
        "trusted": true,
        "id": "Z7yjCV1Hs93j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embedding_matrix, corrected, words_not_found = build_matrix(nb_words, embed_size)\n",
        "embedding_matrix, corrected, words_not_found = build_matrix_1(nb_words, embed_size, correction_map)\n",
        "\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "062ca523-38de-4319-ac39-5d271543496a",
        "_cell_guid": "75c04b8c-fc8d-4dcf-a18d-425ce06fbf9e",
        "trusted": true,
        "id": "6dogh3SDs93m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(corrected))\n",
        "print(corrected)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "17d6ad0b-3e36-44e5-9997-cfb128d92597",
        "_cell_guid": "bcd50d71-55e4-42ed-916d-964ef9f32085",
        "trusted": true,
        "id": "i8y1DW7us93o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(words_not_found))\n",
        "print(words_not_found)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a203042a-8d28-4e46-991d-b8baeacc7a11",
        "_cell_guid": "a6d3b185-717f-4730-93ad-05d411d51925",
        "trusted": true,
        "id": "MQa4pL1Ns93s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('embedding_matrix.npy', embedding_matrix)\n",
        "\n",
        "del embedding_matrix, words_not_found, corrected\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "85a53955-8216-4dd0-b584-a3fb00ad8bb2",
        "_cell_guid": "b264cbbb-f6c4-4354-9102-45e291725d6c",
        "trusted": true,
        "id": "JA0OkJ3Ys93v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.load('x_train.npy')\n",
        "x_test = np.load('x_test.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "embedding_matrix = np.load('embedding_matrix.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0fa83d10-afac-43ee-ad24-0d8fab659752",
        "_cell_guid": "cc9559fd-40d7-4bf5-bdbe-41117c43ea7e",
        "trusted": true,
        "id": "msuoBdsys931",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "LSTM_UNITS = 40\n",
        "DENSE_HIDDEN_UNITS = 6 * LSTM_UNITS\n",
        "    \n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, embedding_matrix, output_dim):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    embed_size = embedding_matrix.shape[1]\n",
        "\n",
        "    self.embedding = nn.Embedding(max_features, embed_size)\n",
        "    self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "    self.embedding.weight.requires_grad = False\n",
        "    self.embedding_dropout = nn.Dropout2d(0.5)\n",
        "\n",
        "    self.lstm = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
        "    self.gru = nn.GRU(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
        "\n",
        "    self.linear_out = nn.Linear(DENSE_HIDDEN_UNITS, output_dim)\n",
        "        \n",
        "  def forward(self, x):\n",
        "    h_embedding = self.embedding(x)\n",
        "\n",
        "    embeddings = h_embedding.unsqueeze(2)    # (N, T, 1, K)\n",
        "    embeddings = embeddings.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
        "    embeddings = self.embedding_dropout(embeddings)  # (N, K, 1, T), some features are masked\n",
        "    embeddings = embeddings.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
        "    h_embedding = embeddings.squeeze(2)  # (N, T, K)\n",
        "\n",
        "    h_lstm, _ = self.lstm(h_embedding)\n",
        "    h_gru, _ = self.gru(h_lstm)\n",
        "    h_gru_last = h_gru[:, -1, :]\n",
        "\n",
        "    avg_pool = torch.mean(h_gru, 1)\n",
        "    max_pool, _ = torch.max(h_gru, 1)\n",
        "\n",
        "    hidden = torch.cat((avg_pool, h_gru_last, max_pool), 1)\n",
        "\n",
        "    # sigmoid layer included within BCEWithLogitLoss\n",
        "    result = self.linear_out(hidden)\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5c78f3b0-90e7-4b96-a32d-e005efd463a9",
        "_cell_guid": "bf23c238-2500-4780-88ce-1287f76f6b2b",
        "trusted": true,
        "id": "8QeBUkMNs934",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_d = NeuralNet(embedding_matrix, y_train.shape[-1])\n",
        "print(model_d)\n",
        "del model_d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4979537a-e19d-4a25-a588-a9fc4fab8062",
        "_cell_guid": "0f42aa51-0091-44c1-8e1b-91f8b489c75d",
        "trusted": true,
        "id": "kSUEFzc6s936",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "# from sklearn.metrics import roc_auc_score\n",
        "# import copy\n",
        "# import time\n",
        "\n",
        "# def sigmoid(x):\n",
        "#     return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# def train_model(model_obj, x_train, y_train, x_test, output_dim, loss_fn, seed, lr=0.001, batch_size=32, \n",
        "#                 n_epochs=7):\n",
        "    \n",
        "#     x_tra, x_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=seed)\n",
        "    \n",
        "#     train = torch.utils.data.TensorDataset(torch.tensor(x_tra, dtype=torch.long).cuda(), torch.tensor(y_tra, dtype=torch.float32).cuda())\n",
        "#     valid = torch.utils.data.TensorDataset(torch.tensor(x_val, dtype=torch.long).cuda(), torch.tensor(y_val, dtype=torch.float32).cuda())\n",
        "      \n",
        "#     train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\n",
        "#     valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "#     test_loader = torch.utils.data.DataLoader(torch.tensor(x_test, dtype=torch.long).cuda(), batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "#     best_score = 0.\n",
        "#     wait_count = 0\n",
        "#     test_preds = np.zeros((len(x_test), output_dim))\n",
        "    \n",
        "#     model = copy.deepcopy(model_obj)\n",
        "#     model.cuda()\n",
        "    \n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "#     scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.6 ** epoch)\n",
        "\n",
        "#     for epoch in range(n_epochs):\n",
        "#         start_time = time.time()\n",
        "        \n",
        "#         model.train()\n",
        "#         avg_loss = 0.\n",
        "        \n",
        "#         for x_batch, y_batch in tqdm(train_loader):\n",
        "#             y_pred = model(x_batch)\n",
        "#             loss = loss_fn(y_pred, y_batch)\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             avg_loss += loss.item() / len(train_loader)\n",
        "            \n",
        "#         model.eval()\n",
        "#         valid_preds = np.zeros((len(y_val), output_dim))\n",
        "#         avg_val_loss = 0.\n",
        "        \n",
        "#         for i, (x_batch, y_batch) in tqdm(enumerate(valid_loader), total=len(valid_loader), leave=False):\n",
        "#             y_pred = model(x_batch).detach()\n",
        "#             avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "#             valid_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())\n",
        "            \n",
        "#         roc_auc_val = roc_auc_score(y_val, valid_preds)\n",
        "        \n",
        "#         if roc_auc_val > best_score:\n",
        "#             print('Score improved from {:.4f} to {:.4f}'.format(best_score, roc_auc_val))\n",
        "#             best_score = roc_auc_val\n",
        "#             wait_count = 0\n",
        "#             for i, (x_batch) in tqdm(enumerate(test_loader), total=len(test_loader), leave=False):\n",
        "#                 y_pred = sigmoid(model(x_batch).detach().cpu().numpy())\n",
        "#                 test_preds[i * batch_size:(i+1) * batch_size] = y_pred\n",
        "#         else:\n",
        "#             wait_count += 1\n",
        "#             if wait_count > 3:\n",
        "#                 print('Early stopping with score {:.4f}'.format(best_score))\n",
        "#                 break\n",
        "        \n",
        "#         scheduler.step()\n",
        "#         elapsed_time = time.time() - start_time\n",
        "#         print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t ROC-AUC Val Score={:.4f} \\t time={:.2f}s'.format(\n",
        "#           epoch + 1, n_epochs, avg_loss, avg_val_loss, roc_auc_val, elapsed_time))\n",
        "          \n",
        "#     del model, optimizer, scheduler, loss\n",
        "#     torch.cuda.empty_cache()\n",
        "    \n",
        "#     return test_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "417e7065-7581-4d27-b1c7-765c57375c94",
        "_cell_guid": "7fe807ec-24e8-4669-b1ff-d490a7b06c95",
        "trusted": true,
        "id": "WPHbikI9s938",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import copy\n",
        "import time\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def train_model(model_obj, x_train, y_train, x_test, output_dim, loss_fn, seed, lr=0.001, batch_size=32, \n",
        "                n_epochs=7, n_splits=10):\n",
        "    \n",
        "    batch_size_1 = 4 * batch_size\n",
        "    x_test_torch = torch.tensor(x_test, dtype=torch.long).cuda()\n",
        "    test_loader = torch.utils.data.DataLoader(x_test_torch, batch_size=batch_size_1, shuffle=False)\n",
        "    \n",
        "    test_preds = np.zeros((len(x_test), output_dim))\n",
        "    all_roc_auc = []\n",
        "    splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed).split(x_train, y_train.sum(axis=1) > 0))\n",
        "    \n",
        "    for i, (train_idx, valid_idx) in enumerate(splits):\n",
        "        x_train_fold = torch.tensor(x_train[train_idx], dtype=torch.long).cuda()\n",
        "        y_train_fold = torch.tensor(y_train[train_idx], dtype=torch.float32).cuda()\n",
        "        x_val_fold = torch.tensor(x_train[valid_idx], dtype=torch.long).cuda()\n",
        "        y_val_fold = torch.tensor(y_train[valid_idx], dtype=torch.float32).cuda()\n",
        "\n",
        "        model = copy.deepcopy(model_obj)\n",
        "        model.cuda()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.7 ** (epoch/3))\n",
        "\n",
        "        train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
        "        valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
        "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size_1, shuffle=False)\n",
        "\n",
        "        best_score = 0.\n",
        "        wait_count = 0\n",
        "        test_preds_fold = np.zeros((len(x_test), output_dim))\n",
        "\n",
        "        print('Fold: ', i+1)\n",
        "        for epoch in range(n_epochs):\n",
        "            start_time = time.time()\n",
        "\n",
        "            model.train()\n",
        "            avg_loss = 0.\n",
        "\n",
        "            for x_batch, y_batch in tqdm(train_loader):\n",
        "                y_pred = model(x_batch)\n",
        "                loss = loss_fn(y_pred, y_batch)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "            model.eval()\n",
        "            valid_preds_fold = np.zeros((x_val_fold.size(0), output_dim))\n",
        "            avg_val_loss = 0.\n",
        "\n",
        "            for i, (x_batch, y_batch) in tqdm(enumerate(valid_loader), total=len(valid_loader), leave=False):\n",
        "                y_pred = model(x_batch).detach()\n",
        "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "                valid_preds_fold[i * batch_size_1:(i+1) * batch_size_1] = sigmoid(y_pred.cpu().numpy())\n",
        "\n",
        "            roc_auc_val = roc_auc_score(y_val_fold.detach().cpu().numpy(), valid_preds_fold)\n",
        "\n",
        "            if roc_auc_val > best_score:\n",
        "                print('Score improved from {:.4f} to {:.4f}'.format(best_score, roc_auc_val))\n",
        "                best_score = roc_auc_val\n",
        "                wait_count = 0\n",
        "                torch.save(model.state_dict(), 'best_model.pt')\n",
        "            else:\n",
        "                wait_count += 1\n",
        "                if wait_count > 3:\n",
        "                    print('Early stopping with score {:.4f}'.format(best_score))\n",
        "                    break\n",
        "\n",
        "            scheduler.step()\n",
        "            elapsed_time = time.time() - start_time\n",
        "            print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t ROC-AUC Val Score={:.4f} \\t time={:.2f}s'.format(\n",
        "                epoch + 1, n_epochs, avg_loss, avg_val_loss, roc_auc_val, elapsed_time))\n",
        "\n",
        "        model.load_state_dict(torch.load('best_model.pt'))\n",
        "        all_roc_auc.append(best_score)\n",
        "\n",
        "        for i, (x_batch) in tqdm(enumerate(test_loader), total=len(test_loader), leave=False):\n",
        "            y_pred = sigmoid(model(x_batch).detach().cpu().numpy())\n",
        "            test_preds_fold[i * batch_size_1:(i+1) * batch_size_1] = y_pred\n",
        "\n",
        "        test_preds += test_preds_fold / len(splits)\n",
        "        del model, optimizer, scheduler, loss\n",
        "        torch.cuda.empty_cache()\n",
        "        print('Latest ROC-AUC Stack: ', all_roc_auc)\n",
        "         \n",
        "    print('All folds done. Average ROC_AUC={:.4f}'.format(np.average(all_roc_auc)))\n",
        "    return test_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e61d11f6-e884-4c09-b578-0b60e57b3725",
        "_cell_guid": "3e65bb55-a07c-4e0b-a351-e3001b631a15",
        "trusted": true,
        "id": "LgTz05fqs93-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed=1234):\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "\n",
        "NUM_MODELS = 1\n",
        "\n",
        "all_test_preds = []\n",
        "\n",
        "for model_idx in range(NUM_MODELS):\n",
        "  \n",
        "  print('Model ', model_idx+1)\n",
        "  SEED = 1234+((model_idx+1)*7)\n",
        "  seed_everything(SEED)\n",
        "  model = NeuralNet(embedding_matrix, y_train.shape[-1])\n",
        "  \n",
        "  test_preds = train_model(model, x_train, y_train, x_test, output_dim=y_train.shape[-1], \n",
        "                                        loss_fn=nn.BCEWithLogitsLoss(reduction='mean'), seed=SEED)\n",
        "  \n",
        "  all_test_preds.append(test_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4e3faede-72c3-4793-bdc9-8dc9dae0dae8",
        "_cell_guid": "c2366c5b-6063-4a26-8286-1cfd6111dc3c",
        "trusted": true,
        "id": "kPBuKoYZs94A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submid = pd.DataFrame({'id': test['id']})\n",
        "submission = pd.concat([submid, pd.DataFrame(np.mean(all_test_preds, axis=0), columns = toxicity_columns)], axis=1)\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}